# -*- coding: utf-8 -*-
"""MNIST_DD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t55jXva3GlAC4_wBdIPZOtflSlkWj6Sg
"""

from tensorflow import keras
print('keras_version = ', keras.__version__)

from keras import models # models.py
from keras import layers
from keras import optimizers

from keras.datasets import mnist # /keras/datasets/mnist
#from keras.utils import to_categorical # /keras/utils/np_utils.py def to_categorical
from keras.utils.np_utils import to_categorical
#import numpy as np
from matplotlib import pyplot as plt

#(train_images, train_labels), (tes_images, test_labels) = keras.datasets.mnist.load_data()
(train_images, train_labels), (test_images, test_labels) = mnist.load_data() # mnist.py def load_data() 
# Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz

train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))

train_images = train_images.astype('float32')/255
test_images = test_images.astype('float32')/255

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

itrain = 10000
itest = 2000

train_images, train_labels = train_images[:itrain], train_labels[:itrain]
test_images, test_labels = test_images[:itest], test_labels[:itest]

model = models.Sequential()
# model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))
# model.add(layers.MaxPool2D((2,2)))
# model.add(layers.Conv2D(64, (3,3), activation='relu'))
# model.add(layers.MaxPool2D((2,2)))
# model.add(layers.Conv2D(64, (3,3), activation='relu'))

model.add(layers.Flatten(input_shape=(28,28,1)))
# model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
model.summary()

# from tensorflow.keras import optimizers
# sgd = optimizers.SGD(learning_rate=0.001, momentum=0.9)

model.compile(optimizer='RMSprop', # or rmsprop
              loss='categorical_crossentropy',
              metrics=['accuracy'])

hist = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))

acc = hist.history['accuracy']
loss = hist.history['loss']
val_acc = hist.history['val_accuracy']
val_loss = hist.history['val_loss']
epochs = range(1, len(acc)+1)

plt.ylim(0., 1.5)
plt.plot(epochs, acc, 'blue', label='train acc')
plt.plot(epochs, val_acc, 'orange', label='val acc')
plt.legend(loc='lower right')
plt.show()

plt.ylim(0., 1.0)
plt.plot(epochs, loss, 'blue', label='train loss')
plt.plot(epochs, val_loss, 'orange', label='val loss')
plt.legend(loc='upper right')
plt.show()
